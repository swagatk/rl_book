@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{norris1998markov,
  title={Markov chains},
  author={Norris, James R},
  number={2},
  year={1998},
  publisher={Cambridge university press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@article{jang2019q,
  title={Q-learning algorithms: A comprehensive classification and applications},
  author={Jang, Beakcheol and Kim, Myeonghwi and Harerimana, Gaspard and Kim, Jong Wook},
  journal={IEEE access},
  volume={7},
  pages={133653--133667},
  year={2019},
  publisher={IEEE}
}

@article{haney2020applied,
  title={Applied artificial intelligence in modern warfare and national security policy},
  author={Haney, Brian Seamus},
  journal={Hastings Sci. \& Tech. LJ},
  volume={11},
  pages={61},
  year={2020},
  publisher={HeinOnline}
}

@article{skinner1971operant,
  title={Operant conditioning},
  author={Skinner, Burrhus F},
  journal={The encyclopedia of education},
  volume={7},
  pages={29--33},
  year={1971},
  publisher={Macmillan and Free Press New York}
}

@article{li2017deep,
  title={Deep reinforcement learning: An overview},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1701.07274},
  year={2017}
}

@article{franccois2018introduction,
  title={An introduction to deep reinforcement learning},
  author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={3-4},
  pages={219--354},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{bellman1966dynamic,
  title={Dynamic programming},
  author={Bellman, Richard},
  journal={Science},
  volume={153},
  number={3731},
  pages={34--37},
  year={1966},
  publisher={American Association for the Advancement of Science}
}

@MISC{gym,
  author = {{Farama Foundation}},
  title = {Gymnasium},
  howpublished = {\url{https://gymnasium.farama.org/}},
  otherinfo = {2023}
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}

@article{maller2009ornstein,
  title={Ornstein--Uhlenbeck processes and extensions},
  author={Maller, Ross A and M{\"u}ller, Gernot and Szimayer, Alex},
  journal={Handbook of financial time series},
  pages={421--437},
  year={2009},
  publisher={Springer}
}

@article{schulman2015trust,
  title={Trust Region Policy Optimization},
  author={Schulman, John},
  journal={arXiv preprint arXiv:1502.05477},
  year={2015}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@incollection{sewak2019actor,
  title={Actor-critic models and the A3C: The asynchronous advantage actor-critic model},
  author={Sewak, Mohit},
  booktitle={Deep reinforcement learning: frontiers of artificial intelligence},
  pages={141--152},
  year={2019},
  publisher={Springer}
}
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{plappert2018multi,
  title={Multi-goal reinforcement learning: Challenging robotics environments and request for research},
  author={Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and others},
  journal={arXiv preprint arXiv:1802.09464},
  year={2018}
}



@MISC{fetchreachgym,
  author = {{Gymnasium-Robotics}},
  title = {Fetch Reach Gym Environment},
  howpublished = {\url{https://robotics.farama.org/envs/fetch/reach/}},
  otherinfo = {Last Accessed: July 29, 2024}
}

